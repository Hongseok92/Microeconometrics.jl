var documenterSearchIndex = {"docs":
[{"location":"contributing/#Contributing-1","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"This section helps you specify your own estimator. You can then submit a pull request to add it to Microeconometrics.jl!","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We will analyze the implementation of OLS. Although it is a simple model, others follow the same steps.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"The first step is defining the output struct:","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"mutable struct OLS <: MLE\n\n    sample::Microdata     # estimation sample\n    β::Vector{Float64}    # coefficient vector\n    V::AbstractMatrix{Float64}    # variance matrix\n\n    OLS() = new()\nend","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"Every estimator has these fields. Internal utilities rely on them. Some have additional fields (e.g., IV stores the estimation method and the weight matrix). Two-stage models store the estimators for each stage instead.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We then define an uninitialized constructor:","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"function OLS(MD::Microdata)\n    obj        = OLS()\n    obj.sample = MD\n    return obj\nend","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"The functions _fit! and _vcov! will later set β and V.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"The next step is overloading the function fit from StatsBase.jl:","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"function fit(::OLS, MD::Microdata; novar::Bool = false)\n\n    obj = OLS(MD)\n\n    _fit!(obj, getweights(obj))\n    novar || _vcov!(obj, getcorr(obj), getweights(obj))\n\n    return obj\nend","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"For OLS, we only need to initialize the output object and pass it to _fit! and _vcov!. (It is not actually necessary to extend fit unless you need to perform additional steps before the estimation, as the fallback will suffice.) Note the utilities getcorr and getweights.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We can now estimate the coefficients. For efficiency, we write separate functions for unweighted and weighted data.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"function _fit!(obj::OLS, w::UnitWeights)\n    y     = getvector(obj, :response)\n    x     = getmatrix(obj, :control)\n    obj.β = x \\ y\nend\n\nfunction _fit!(obj::OLS, w::AbstractWeights)\n    y     = getvector(obj, :response)\n    x     = getmatrix(obj, :control)\n    v     = Diagonal(w) * x\n    obj.β =  (v' * x) \\ (v' * y)\nend","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"Notice the internal utilities getvector and getmatrix. Their first argument is a Microdata or a model structure. The following arguments are the model components of interest. You can request several components from getmatrix at once. For example, IV needs x = getmatrix(obj, :treatment, :control) and z = getmatrix(obj, :instrument, :control). A single matrix is returned in all cases.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"warning: Warning\ngetvector and getmatrix return views into the underlying data matrix. You should never modify their output, as you would irremediably alter the data. If you need to perform an in-place operation, make a copy beforehand.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"OLS does not require nonlinear optimization. If your estimator needs it, you can use the tools of Optim.jl. See the implementation of Logit for an example.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We must now define score and jacobian. These functions are the building blocks of the variance estimator. The score is the vector of moment conditions. For OLS, it is −xᵢ (yᵢ − xᵢ'β) (the derivative of the objective function). score should return the matrix of score vectors in row form. The Jacobian matrix is the derivative of the moment conditions. For OLS, it is xᵢ xᵢ'. jacobian should return the weighted sum of Jacobians (i.e., the expected Jacobian × the number of observations).","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"function score(obj::OLS)\n    x = copy(getmatrix(obj, :control))\n    û = residuals(obj)\n    return - x .* û\nend\n\nfunction jacobian(obj::OLS, w::UnitWeights)\n    x = getmatrix(obj, :control)\n    return x' * x\nend\n\nfunction jacobian(obj::OLS, w::AbstractWeights)\n    x = getmatrix(obj, :control)\n    v = copy(x) .* w\n    return x' * v\nend","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"score returns the score for each observation, so it ignores weights. jacobian returns an expectation; therefore, it must account for weights.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We do not need to extend _vcov!. The default method will call score and jacobian and construct the appropriate estimator, accounting for the correlation structure of the data and the type of weights.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We now overload predict:","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"predict(obj::OLS, MD::Microdata) = getmatrix(MD, :control) * obj.β","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"The next step is optional. We extend jacobexp, which computes the derivative of fitted values.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"jacobexp(obj::OLS) = copy(getmatrix(obj, :control))","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"jacobexp is only necessary when the estimator serves as the first stage of a two-stage estimator. By extending it, you make your estimator available to two-stage estimators.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"We conclude with a function to retrieve coefficient labels:","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"coefnames(obj::OLS) = getnames(obj, :control)","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"The syntax of getnames is similar to that of getmatrix.","category":"page"},{"location":"contributing/#","page":"Contributing","title":"Contributing","text":"You can implement additional methods. For example, Microeconometrics.jl extends r2, adjr2, loglikelihood, etc. to OLS.","category":"page"},{"location":"estimators/#Estimators-1","page":"Estimators","title":"Estimators","text":"","category":"section"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The function fit estimates models. It returns a model structure, which contains the estimation sample, the coefficients and their covariance matrix. For example, the output of fit(OLS, MD) has type OLS. Some have additional fields: e.g., two-stage models carry estimates from the first stage and GMM models carry the inverse of the weight matrix.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"note: Note\nIf you only need coefficients, pass novar = true to fit.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"Model structures are subtypes of broader abstract types, such as MLE or GMM, which are ultimately instances of RegressionModel. The type hierarchy is:","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"RegressionModel\n    ParModel\n        GMM\n        MLE\n    TwoStageModel","category":"page"},{"location":"estimators/#Linear-regression-1","page":"Estimators","title":"Linear regression","text":"","category":"section"},{"location":"estimators/#Ordinary-least-squares-1","page":"Estimators","title":"Ordinary least squares","text":"","category":"section"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(OLS, MD::Microdata)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response and control. See the documentation for linear IV if Microdata includes a treatment. OLS is a subtype of MLE.","category":"page"},{"location":"estimators/#Linear-IV-1","page":"Estimators","title":"Linear IV","text":"","category":"section"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(IV, MD::Microdata; method::String = \"TSLS\")","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The following methods are currently implemented:","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"method = \"TSLS\": two-stage least squares;\nmethod = \"Two-step GMM\": optimally weighted two-stage GMM with robust covariance matrix;\nmethod = \"Optimal GMM\": optimally weighted two-stage GMM with simplified covariance matrix.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"Additional methods are available for convenience:","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"method = \"OLS\": linear regression of the outcome on the treatment and controls;\nmethod = \"First stage\": linear regression of the treatment on the instruments and controls;\nmethod = \"Reduced form\": linear regression of the outcome on the instruments and controls.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response, treatment, control and instrument. IV is a subtype of GMM.","category":"page"},{"location":"estimators/#Binary-choice-1","page":"Estimators","title":"Binary choice","text":"","category":"section"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(Logit, MD::Microdata)\nfit(Probit, MD::Microdata)\nfit(Cloglog, MD::Microdata)\nfit(Gompit, MD::Microdata)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response and control. The outcome should be binary. The model structures are subtypes of MLE.","category":"page"},{"location":"estimators/#Count-data-1","page":"Estimators","title":"Count data","text":"","category":"section"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(Poisson, MD::Microdata; novar::Bool = false)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response and control. The Microdata may contain an offset. See the documentation for linear IV if Microdata includes a treatment. The outcome must be weakly positive. Poisson is a subtype of MLE.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(IVPoisson, MD::Microdata; novar::Bool = false, method::String = \"One-step GMM\")\nfit(Mullahy, MD::Microdata; novar::Bool = false, method::String = \"One-step GMM\")","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"IVPoisson fits the exponential conditional mean model with additive errors. Mullahy fits the exponential conditional mean model with multiplicative errors (Mullahy, 1997).","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The following methods are currently implemented:","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"method = \"One-step GMM\": unweighted one-stage GMM;\nmethod = \"TSLS\": one-stage GMM with the average outer product of the instrument vector as weight matrix;\nmethod = \"Two-step GMM\": optimally weighted two-stage GMM with robust covariance matrix;\nmethod = \"Optimal GMM\": optimally weighted two-stage GMM with simplified covariance matrix.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The models are estimated with the Gauss–Newton algorithm. The first stage of the two-stage specifications is estimated with the average outer product of the instrument vector as weight matrix.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"Additional methods are available for convenience:","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"method = \"Poisson\": Poisson regression of the outcome on the treatment and controls;\nmethod = \"Reduced form\": Poisson regression of the outcome on the instruments and controls.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response, treatment, control and instrument. The Microdata may contain an offset. The outcome must be weakly positive. IVPoisson and Mullahy are subtypes of GMM.","category":"page"},{"location":"estimators/#Reweighting-methods-1","page":"Estimators","title":"Reweighting methods","text":"","category":"section"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"note: Note\nAll reweighting models require the specification of a first stage. They come in two flavors. In the first, you specify the first-stage model. In the second, you pass a previously fitted model. The latter is more verbose, but it allows you to customize and reuse the first stage.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(IPW, M₁::Type{Micromodel}, MD::Microdata; trim::AbstractFloat = 0.0)\nfit(IPW, M₁::Micromodel, MD::Microdata; trim::AbstractFloat = 0.0)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"IPW estimates average treatment effects by inverse probability weighting. In a first stage, we use model M₁ to forecast the conditional probability of treatment take-up and construct estimation weights. In the second stage, we regress the outcome on the treatment and an intercept by weighted least squares. The intercept gives the mean outcome of the untreated. We ignore observations whose score is below trim or above 1 - trim (see Crump et al. (2009)).","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response, treatment and control. The treatment must be binary. IPW is a subtype of TwoStageModel.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(Abadie, M₂::Type{ParModel}, M₁::Type{Micromodel}, MD::Microdata; trim::AbstractFloat = 0.0, kwargs...)\nfit(Abadie, M₂::Type{ParModel}, M₁::Micromodel, MD::Microdata; trim::AbstractFloat = 0.0 kwargs...)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"Abadie estimates local average response functions according to Abadie (2003). In a first stage, we use model M₁ to forecast the conditional probability of instrument take-up and construct estimation weights. In the second stage, we fit M₂ with the weights from the first stage. Keywords customize the second-stage estimator. We ignore observations whose score is below trim or above 1 - trim (see Crump et al. (2009)).","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response, treatment, control and instrument. The treatment and the instrument must be binary. Abadie is a subtype of TwoStageModel.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(FrölichMelly, M₁::Type{Micromodel}, MD::Microdata; trim::AbstractFloat = 0.0)\nfit(FrölichMelly, M₁::Micromodel, MD::Microdata; trim::AbstractFloat = 0.0)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"This model estimates unconditional local average effects according to Frölich and Melly (2013). In a first stage, we use model M₁ to forecast the conditional probability of instrument take-up and construct estimation weights. In the second stage, we regress the outcome on the treatment and an intercept by weighted least squares. The intercept gives mean outcome of untreated compliers. We ignore observations whose score is below trim or above 1 - trim (see Crump et al. (2009)).","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response, treatment, control and instrument. The treatment and the instrument must be binary. FrölichMelly is a subtype of TwoStageModel.","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"fit(Tan, M₁::Type{Micromodel}, MD::Microdata; trim::AbstractFloat = 0.0)\nfit(Tan, M₁::Micromodel, MD::Microdata; trim::AbstractFloat = 0.0)","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"This model estimates the unconditional local average treatment effects according to Tan (2006). In a first stage, we use model M₁ to forecast the conditional probability of instrument take-up and construct estimation weights. In the second stage, we regress the outcome on the treatment and an intercept by weighted two-stage least squares. The intercept gives mean outcome of untreated compliers. We ignore observations whose score is below trim or above 1 - trim (see Crump et al. (2009)).","category":"page"},{"location":"estimators/#","page":"Estimators","title":"Estimators","text":"The Microdata must contain: response, treatment, control and instrument. The treatment and the instrument must be binary. Tan is a subtype of TwoStageModel.","category":"page"},{"location":"bootstrapping/#Bootstrapping-1","page":"Bootstrapping","title":"Bootstrapping","text":"","category":"section"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"This package does not provide support for bootstrap standard errors at the moment. Nonetheless, it is possible to bootstrap with the existing tools. This tutorial provides some sample code.","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"We first load some packages:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"using StatsBase\r\nusing DataFrames\r\nusing CSV\r\nusing Microeconometrics","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"We then set up the problem:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"S        = CSV.read(joinpath(datadir, \"auto.csv\")) ;\r\nS[:gpmw] = ((1.0 ./ S[:mpg]) ./ S[:weight]) * 100000 ;\r\nM        = Dict(:response => \"gpmw\", :control => \"foreign + 1\") ;\r\nD        = Microdata(S, M) ;","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"Next, we obtain the coefficient estimates:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"E = fit(OLS, D, novar = true) ;","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"We can now set up the bootstrap:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"srand(0101)\r\n\r\nreps = 1000 ;\r\nn    = nobs(E) ;\r\nwgts = fill(0, n) ;\r\nB    = Array{Float64}(reps, dof(E)) ;","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"The vector wgts will translate the draw of a bootstrap sample into an input for Microdata. The matrix B will contain the sample of coefficient estimates. Don't forget to set the seed for the sake of reproducibility!","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"The algorithm is:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"for b = 1:reps\r\n\r\n    wgts .= 0\r\n    draw  = rand(1:n, n)\r\n\r\n    for d in draw\r\n        wgts[d] += 1\r\n    end\r\n\r\n    Db      = Microdata(S, M, weights = fweights(wgts))\r\n    Eb      = fit(OLS, Db, novar = true)\r\n    B[b, :] = coef(Eb)'\r\nend","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"Note that we do not compute the covariance matrix at each step, which saves us some time.","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"We can finally see the results:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"E.V = cov(B) ;\r\ncoeftable(E)","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"The output is:","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"                   Estimate  St. Err.   t-stat.   p-value      C.I. (95%)\r\nforeign: Foreign     0.2462    0.0682    3.6072    0.0003    0.1124  0.3799\r\n(Intercept)           1.609    0.0237   67.9372    <1e-99    1.5626  1.6554","category":"page"},{"location":"bootstrapping/#","page":"Bootstrapping","title":"Bootstrapping","text":"You can easily adapt this code to more complex problems (e.g., critical values) or parallelize it for additional speed!","category":"page"},{"location":"methods/#Methods-1","page":"Methods","title":"Methods","text":"","category":"section"},{"location":"methods/#","page":"Methods","title":"Methods","text":"This package supports the methods for regression models of StatsBase.jl.","category":"page"},{"location":"methods/#","page":"Methods","title":"Methods","text":"The following functions are available for all models: nobs and response.","category":"page"},{"location":"methods/#","page":"Methods","title":"Methods","text":"The following functions are available for parametric models: dof, dof_residual, coef, stderror, vcov, confint and coefnames. Note that all methods refer to the second stage of two-stage models.","category":"page"},{"location":"methods/#","page":"Methods","title":"Methods","text":"The following functions are available for maximum-likelihood estimators: deviance, nulldeviance, loglikelihood, nullloglikelihood, r2 and adjr2. There are also R² methods for OLS and IV. The following functions are available from StatsBase.jl: aic, aicc and bic.","category":"page"},{"location":"methods/#","page":"Methods","title":"Methods","text":"Most models support predict and its alias fitted. Support for residuals depends on the availability of fitted. Out-of-sample forecast is supported.","category":"page"},{"location":"model_specification/#Model-specification-1","page":"Model specification","title":"Model specification","text":"","category":"section"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"Before you estimate a model, you must load the data and specify the role of each variable in the model. This packages defines Microdata for that purpose.","category":"page"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"Microdata(\n        DF::DataFrame,\n        model::Dict{Symbol, String};\n        hints::Dict{Symbol, TermOrTerms},\n        subset::AbstractVector{Bool},\n        weights::AbstractWeights = UnitWeights(size(DF, 1))\n        corr::CorrStructure,\n    )","category":"page"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"To construct a Microdata, two arguments are compulsory: a DataFrame, which contains the data, and a dictionary, which specifies the components of the model of interest. To construct this dictionary, use the macro @micromodel.","category":"page"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"All regression models need a response, but other requirements may vary. (Check the documentation!) For example, OLS asks for response and control. In defining these sets, follow the syntax of Formula. (See the tutorial for examples.) Conventional sets include:","category":"page"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"response: the response (a.k.a. outcome or dependent variable);\ncontrol: exogenous explanatory variables (n.b.: you must explicitly include intercepts, + 1);\noffset: an exogenous variable whose coefficient is constrained to unity;\ntreatment: endogenous explanatory variables;\ninstrument: instrumental variables (i.e. excluded exogenous variables).","category":"page"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"As for the keywords:","category":"page"},{"location":"model_specification/#","page":"Model specification","title":"Model specification","text":"hints: a dictionary from column labels to schemas or contrasts.\nsubset determines the estimation sample. Set an entry to true if the corresponding row of DF should be included and false if it should be excluded. This keyword is useful if you are comparing subgroups and observations in different subgroups may correlate (e.g., they may belong to the same cluster). chow_test will take that correlation into account if the Microdata were constructed with subset.\nweights is a weight vector. Except for frequency weights, the weight vector is normalized to sum up to the number of observations in the sample.\ncorr is a correlation structure.","category":"page"},{"location":"hypothesis_tests/#Hypothesis-tests-1","page":"Hypothesis tests","title":"Hypothesis tests","text":"","category":"section"},{"location":"hypothesis_tests/#Significance-tests-1","page":"Hypothesis tests","title":"Significance tests","text":"","category":"section"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"tstat(model::Union{GMM, ParModel, TwoStageModel, ParEstimate})","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"This function returns the t-statistic (i.e. the ratio of coefficients to standard error).","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"pval(model::Union{GMM, ParModel, TwoStageModel, ParEstimate})","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"This function returns the p-value of a two-sided significance test.","category":"page"},{"location":"hypothesis_tests/#Hausman-test-1","page":"Hypothesis tests","title":"Hausman test","text":"","category":"section"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"hausman_test(\n        model₁::Union{GMM, ParModel, TwoStageModel},\n        model₂::Union{GMM, ParModel, TwoStageModel},\n        names::Vector{String} = intersect(coefnames(obj₁), coefnames(obj₂))\n)","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"This procedure tests the difference in coefficients between two parametric models (Hausman, 1984). Both models must have been estimated on the sample. It can be used in replacement of the Sobel test. This implementation is based on the GMM representation of the joint estimation problem (see Subsection 8.3.2 of Cameron and Trivedi (2005)). Neither model need be efficient.","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"The optional argument names specifies the coefficients of interest as they appear on regression tables (be careful with categorical variables!). The output is a ParEstimate, which contains the vector of differences, their covariance matrix and labels.","category":"page"},{"location":"hypothesis_tests/#Chow-test-1","page":"Hypothesis tests","title":"Chow test","text":"","category":"section"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"This procedure tests the difference in coefficients between two parametric models (Hausman, 1984). The models need not have been estimated on the sample. This implementation is based on the GMM representation of the joint estimation problem (see Subsection 8.3.2 of Cameron and Trivedi (2005)).","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"The optional argument names specifies the coefficients of interest as they appear on regression tables (be careful with categorical variables!). The output is a ParEstimate, which contains the vector of differences, their covariance matrix and labels.","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":" chow_test(\n         model₁::Union{GMM, ParModel, TwoStageModel},\n         model₂::Union{GMM, ParModel, TwoStageModel},\n         names::Vector{String} = intersect(coefnames(obj₁), coefnames(obj₂))\n )","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"This function is appropriate when model₁ and model₂ were based on independent samples. For example, the samples might consist of independent observations with no overlap.","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":" chow_test(\n         model₁::Union{GMM, ParModel, TwoStageModel},\n         model₂::Union{GMM, ParModel, TwoStageModel},\n         corr::CorrStructure,\n         names::Vector{String} = intersect(coefnames(obj₁), coefnames(obj₂))\n )","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"This function is appropriate when model₁ and model₂ were based on dependent samples. For example, two clustered samples might have one or more clusters in common. We must then take the correlation across samples within shared clusters into account.","category":"page"},{"location":"hypothesis_tests/#","page":"Hypothesis tests","title":"Hypothesis tests","text":"The correlation structure corr must specify the correlation between all observations of both estimation samples. For instance, you could construct corr for the entire dataset and construct the subsamples via the subset keyword of Microdata.","category":"page"},{"location":"correlation_structures/#Correlation-structures-1","page":"Correlation structures","title":"Correlation structures","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Before fitting the model, you must specify the correlation between observations (a CorrStructure). It determines the calculation of covariance matrices. The default is always Heteroscedastic, i.e. independent but not identically distributed observations.","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"All constructors accept the Boolean keyword corrected (omitted in the following), which defaults to true. If true, a finite-sample adjustment is applied to the covariance matrix. The adjustment factor is n / (n - 1), where n is the number of clusters for clustered data and the number of observations otherwise.","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Four subtypes are currently available: Homoscedastic, Heteroscedastic, Clustered and CrossCorrelated.","category":"page"},{"location":"correlation_structures/#Homoscedastic-1","page":"Correlation structures","title":"Homoscedastic","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Homoscedastic(; expected::Bool = false)","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Observations are independent and identically distributed. The optional keyword argument expected controls the estimation of the covariance matrix of maximum-likelihood estimators: false uses the observed information matrix, whereas \"true\" uses the outer product of the gradient. Only linear and maximum-likelihood estimators support homoscedastic errors.","category":"page"},{"location":"correlation_structures/#Heteroscedastic-1","page":"Correlation structures","title":"Heteroscedastic","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Heteroscedastic()","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Observations are independent, but they may differ in distribution. This structure leads to sandwich covariance matrices (a.k.a. Huber-Eicker-White).","category":"page"},{"location":"correlation_structures/#Clustered-1","page":"Correlation structures","title":"Clustered","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Clustered(DF::DataFrame, cluster::Symbol)","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"Observations are independent across clusters, but they may differ in their joint distribution within clusters. cluster specifies the column of the DataFrame to cluster on.","category":"page"},{"location":"correlation_structures/#CrossCorrelated-1","page":"Correlation structures","title":"CrossCorrelated","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"This structure accommodates other correlation structures. The first argument determines the precise pattern.","category":"page"},{"location":"correlation_structures/#Two-way-clustering-1","page":"Correlation structures","title":"Two-way clustering","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"CrossCorrelated(\"Two-way clustering\", DF::DataFrame, c₁::Symbol, c₂::Symbol)","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"if two observations share any cluster, they may be arbitrarily correlated.","category":"page"},{"location":"correlation_structures/#Correlation-across-time-1","page":"Correlation structures","title":"Correlation across time","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"CrossCorrelated(\"Time\",\r\n        DF::DataFrame,\r\n        time::Symbol,\r\n        bandwidth::Real,\r\n        kernel::Function = parzen\r\n    )","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"The maximum possible correlation between two observations declines with the time difference between them. The actual correlation is arbitrary below that limit. (See Conley (1999).) The bandwidth and the kernel function control the upper bound. time specifies the column of DF that contains the date of each observation (of type Date).","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"The following kernels are predefined for convenience: Bartlett (bartlett), Parzen (parzen), Truncated (truncated) and Tukey-Hanning (tukeyhanning). See Andrews (1991) for formulae.","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"warning: Warning\nThe resulting covariance matrices differ from the Newey-West estimator, which assumes independence across units (though observations for the same unit may correlate across time).","category":"page"},{"location":"correlation_structures/#Correlation-across-space-1","page":"Correlation structures","title":"Correlation across space","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"CrossCorrelated(\"Space\",\r\n        DF::DataFrame,\r\n        latitude::Symbol,\r\n        longitude::Symbol,\r\n        bandwidth::Real,\r\n        kernel::Function = parzen\r\n    )","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"The maximum possible correlation between two observations declines with the spatial distance between them. The actual correlation is arbitrary below that limit. (See Conley (1999).) The bandwidth and the kernel function control the upper bound. latitude and longitude specify the columns of DF that contain the coordinates of each observation in decimal degrees (of type Float64).","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"The following kernels are predefined for convenience: Bartlett (bartlett), Parzen (parzen), Truncated (truncated) and Tukey-Hanning (tukeyhanning). See Andrews (1991) for formulae.","category":"page"},{"location":"correlation_structures/#Correlation-across-time-and-space-1","page":"Correlation structures","title":"Correlation across time and space","text":"","category":"section"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"CrossCorrelated(\"Time and space\",\r\n        DF::DataFrame,\r\n        time::Symbol,\r\n        bandwidth_time::Real,\r\n        latitude::Symbol,\r\n        longitude::Symbol,\r\n        bandwidth_space::Real,\r\n        kernel::Function = parzen\r\n    )","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"The maximum possible correlation between two observations declines with the time difference and the spatial distance between them. The actual correlation is arbitrary below that limit. (See Conley (1999).) The bandwidths and the kernel function control the upper bound. time specifies the column of DF that contains the date of each observation. latitude and longitude specify the columns of DF that contain the coordinates of each observation in decimal degrees (Float64).","category":"page"},{"location":"correlation_structures/#","page":"Correlation structures","title":"Correlation structures","text":"The following kernels are predefined for convenience: Bartlett (bartlett), Parzen (parzen), Truncated (truncated) and Tukey-Hanning (tukeyhanning). See Andrews (1991) for formulae.","category":"page"},{"location":"to_do/#To-do-1","page":"To do","title":"To do","text":"","category":"section"},{"location":"to_do/#","page":"To do","title":"To do","text":"More models;\nMarginal effects for nonlinear models;\nA framework for panel data;\nA framework for semiparametric and nonparametric models;\nWald test;\nLikelihood-based tests.","category":"page"},{"location":"getting_started/#Getting-Started-1","page":"Getting started","title":"Getting Started","text":"","category":"section"},{"location":"getting_started/#Installation-1","page":"Getting started","title":"Installation","text":"","category":"section"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To install the latest release, run:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> Pkg.add(\"Microeconometrics\")","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To update to the latest release, run:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> Pkg.update(\"Microeconometrics\")","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To install the last version, run:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> Pkg.add(PackageSpec(name = \"Microeconometrics\", rev = \"master\"))","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To update to the last version, run:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> Pkg.update(PackageSpec(name = \"Microeconometrics\", rev = \"master\"))","category":"page"},{"location":"getting_started/#Example-I:-OLS-1","page":"Getting started","title":"Example I: OLS","text":"","category":"section"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"For an introduction to the package, let's consider an example: ordinary least squares.","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We first load some modules:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> using CSV\njulia> using DataFrames\njulia> using Microeconometrics","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"Next, we load the data:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> S = CSV.read(\"admit.csv\") ; categorical!(S, :rank) ;","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"This sample is available here, if you wish to replicate this exercise. It comprises 400 observations and four variables (admit, gre, gpa and rank). The second command converts S[:rank] into a categorical array (a.k.a. a factor variable).","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We wish to regress admit on gre, gpa, rank and an intercept. We first specify the model:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> M = @micromodel(response => admit, control => gre + gpa + rank + 1) ;","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"The syntax is due to StatsModels.jl. The @micromodel macro generalizes @formula.","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We then define the correlation structure of the errors. Let's assume that observations are independent and identically distributed, so that errors are homoscedastic:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> C = Homoscedastic() ;","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We now construct the estimation sample:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> D = Microdata(S, M, corr = C) ;","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We can finally fit the model and visualize the results:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> E = fit(OLS, D)\n\n              Estimate  St. Err.   t-stat.   p-value      C.I. (95%)  \ngre             0.0004    0.0002    2.0384    0.0415    0.0000  0.0008\ngpa             0.1555    0.0640    2.4317    0.0150    0.0302  0.2809\nrank: 2        -0.1624    0.0677   -2.3978    0.0165   -0.2951 -0.0296\nrank: 3        -0.2906    0.0702   -4.1365    0.0000   -0.4282 -0.1529\nrank: 4        -0.3230    0.0793   -4.0726    0.0000   -0.4785 -0.1676\n(Intercept)    -0.2589    0.2160   -1.1987    0.2306   -0.6822  0.1644","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"The corresponding code in Stata is:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":". import delimited \"admit.csv\"\n. regress admit gre gpa i.rank","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To obtain summary statistics, we can apply the methods for regression models of StatsBase.jl:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> nobs(e_ols)\n\n400\n\njulia> r2(e_ols)\n\n0.10040062851886422","category":"page"},{"location":"getting_started/#Example-II:-Comparing-models-1","page":"Getting started","title":"Example II: Comparing models","text":"","category":"section"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To illustrate more advanced features, suppose that we want to compare specifications. As a first exercise, we wonder if we could drop the rank fixed effects.","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We start with the full model. We now assume that the data are heteroscedastic. Because it is the default, we need not specify it.","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> M₁ = @micromodel(response => admit, control => gre + gpa + rank + 1) ;\njulia> D₁ = Microdata(S, M₁) ;\njulia> E₁ = fit(OLS, D₁)\n\n              Estimate  St. Err.   t-stat.   p-value      C.I. (95%)  \ngre             0.0004    0.0002    2.0501    0.0404    0.0000  0.0008\ngpa             0.1555    0.0653    2.3833    0.0172    0.0276  0.2834\nrank: 2        -0.1624    0.0729   -2.2266    0.0260   -0.3053 -0.0194\nrank: 3        -0.2906    0.0730   -3.9827    0.0001   -0.4336 -0.1476\nrank: 4        -0.3230    0.0780   -4.1408    0.0000   -0.4759 -0.1701\n(Intercept)    -0.2589    0.2110   -1.2268    0.2199   -0.6725  0.1547","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"Before we estimate the reduced model, we must first redefine the control set:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> M₂ = @micromodel(response => admit, :control => gre + gpa + 1) ;\njulia> D₂ = Microdata(S, M₂) ;","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We can now fit the reduced model:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> E₂ = fit(OLS, D₂)\n\n              Estimate  St. Err.   t-stat.   p-value      C.I. (95%)  \ngre             0.0005    0.0002    2.5642    0.0103    0.0001  0.0010\ngpa             0.1542    0.0650    2.3737    0.0176    0.0269  0.2816\n(Intercept)    -0.5279    0.2087   -2.5293    0.0114   -0.9370 -0.1188","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"The coefficients on gre and gpa seem to be robust. For a formal equality test, we use a Hausman test:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> H = hausman_test(E₁, E₂, [\"gre\", \"gpa\"]) ;\njulia> tstat(H)\n\n2-element Array{Float64,1}:\n  -2.07838\n  0.0749552","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"As it turns out, the difference between the coefficients on gre is statistically significant.","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"To further investigate this result, we wish to estimate separate effects by rank. The keyword subset helps us construct the appropriate Microdata:","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"julia> M = @micromodel(response => admit, control => gre + gpa + 1) ;\n\njulia> I₁ = (S[:rank] .== 1) ;\njulia> D₁ = Microdata(S, M, subset = I₁) ;\njulia> E₁ = fit(OLS, D₁)\n\n              Estimate  St. Err.   t-stat.   p-value      C.I. (95%)  \ngre             0.0006    0.0006    1.0386    0.2990   -0.0005  0.0017\ngpa             0.2508    0.1929    1.3000    0.1936   -0.1273  0.6290\n(Intercept)    -0.6806    0.5662   -1.2021    0.2293   -1.7903  0.4291\n\njulia> I₂ = (S[:rank] .== 2) ;\njulia> D₂ = Microdata(S, M, subset = I₂) ;\njulia> E₂ = fit(OLS, D₂)\n\n              Estimate  St. Err.   t-stat.   p-value      C.I. (95%)  \ngre             0.0004    0.0004    0.8794    0.3792   -0.0004  0.0011\ngpa             0.1771    0.1028    1.7219    0.0851   -0.0245  0.3787\n(Intercept)    -0.4470    0.3641   -1.2277    0.2196   -1.1607  0.2666\n\njulia> H = chow_test(E₁, E₂, [\"gre\", \"gpa\"]) ;\njulia> tstat(H)\n\n2-element Array{Float64,1}:\n  0.334261\n  0.337304","category":"page"},{"location":"getting_started/#","page":"Getting started","title":"Getting started","text":"We used the function chow_test because these estimates are based on different samples. The difference in the effect of gre between ranks 1 and 2 is not significant.","category":"page"},{"location":"estimation_tables/#Estimation-tables-1","page":"Estimation tables","title":"Estimation tables","text":"","category":"section"},{"location":"estimation_tables/#Single-model-1","page":"Estimation tables","title":"Single model","text":"","category":"section"},{"location":"estimation_tables/#","page":"Estimation tables","title":"Estimation tables","text":"coeftable(\n    model::Union{GMM, ParModel, TwoStageModel};\n    digits::Int = 4,\n    level::AbstractFloat = 0.95\n)","category":"page"},{"location":"estimation_tables/#","page":"Estimation tables","title":"Estimation tables","text":"This function displays coefficients, standard errors and other information. The keyword digits controls rounding. The keyword level controls the level of the confidence interval (0.0 for none).","category":"page"},{"location":"estimation_tables/#Multiple-models-1","page":"Estimation tables","title":"Multiple models","text":"","category":"section"},{"location":"estimation_tables/#","page":"Estimation tables","title":"Estimation tables","text":"etable(\n    args...;\n    digits::Int = 4,\n    aux::Union{Function, Nothing} = nothing,\n    stars::AbstractMatrix{Any} = [0.1 \"*\"; 0.05 \"**\"; 0.01 \"***\"]\n)","category":"page"},{"location":"estimation_tables/#","page":"Estimation tables","title":"Estimation tables","text":"This function displays a simple regression table. The keyword arguments are:","category":"page"},{"location":"estimation_tables/#","page":"Estimation tables","title":"Estimation tables","text":"digits: the number of digits on display;\naux: an auxiliary statistic (e.g., stderror), displayed below each coefficient;\nstars: the star scheme.","category":"page"},{"location":"#Microeconometrics.jl-1","page":"Introduction","title":"Microeconometrics.jl","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"This package provides support for microeconometric estimation. It supports complex weighted data and covariance structures (e.g., clustered). Please report bugs by opening an issue. Information about specific versions can be found on the release page.","category":"page"},{"location":"#Supported-estimators-1","page":"Introduction","title":"Supported estimators","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"More models are planned. If your preferred model is not currently available, file an issue or contribute!","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"Linear regression\nOrdinary least squares\nTwo-stage least squares\nLinear GMM\nBinary choice\nLogit\nProbit\nComplementary log-log\nGompit\nCount data\nPoisson\nIV Poisson with additive errors\nIV Poisson with multiplicative errors\nReweighting methods\nInverse probability weighting\nAbadie (2003)\nFrölich and Melly (2013)\nTan (2006)","category":"page"},{"location":"#Package-manual-1","page":"Introduction","title":"Package manual","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Pages = [\n        \"getting_started.md\",\n        \"model_specification.md\",\n        \"correlation_structures.md\",\n        \"estimators.md\",\n        \"methods.md\",\n        \"hypothesis_tests.md\",\n        \"estimation_tables.md\",\n        \"bootstrapping.md\",\n        \"contributing.md\",\n        \"to_do.md\",\n    ]\nDepth = 2","category":"page"}]
}
